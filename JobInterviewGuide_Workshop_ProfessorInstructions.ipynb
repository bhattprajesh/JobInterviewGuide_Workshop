{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643fb416",
   "metadata": {},
   "source": [
    "# üß†üìö Job Interview Guide Workshop\n",
    "\n",
    "![Image Description](./images/OnlineJobInterview.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58423095",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ Learning Objectives\n",
    "- Practice **AI-mediated interview preparation** with a mix of *technical* and *behavioral/scenario-based* questions.\n",
    "- Reinforce core ML topics from the course through **targeted exercises**.\n",
    "- Produce a **graded, personalized study notebook** tailored to your quiz results.\n",
    "- Demonstrate professionalism with **clear documentation** and **version control** (GitHub).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f6e0ac",
   "metadata": {},
   "source": [
    "\n",
    "## üìò Topics Covered (Review Scope)\n",
    "1. **Supervised vs. Unsupervised** learning algorithms  \n",
    "2. **Dependent vs. Independent Variables**  \n",
    "3. **Train / Validation / Test Split** (data leakage, stratification)  \n",
    "4. **Linear Regression**: residuals, linearization  \n",
    "5. **Regression Analysis**: parametric vs. non-parametric, **R¬≤**, **MSE**  \n",
    "6. **Logistic Regression**: intercept, slope, **cross-entropy**  \n",
    "7. **K-Nearest Neighbors (KNN)**: hyperparameters  \n",
    "8. **Decision Trees**: leaf nodes & predictions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716c49f",
   "metadata": {},
   "source": [
    "\n",
    "## üß≠ Workflow (What You Will Do)\n",
    "1. **Collect materials**  \n",
    "   - Copy the workshop folders: `DataStreamVisualization_Workshop`, `LinearRegressionArchitecture_Workshop`, `PerformanceMetricsClassification`, `KNearestNeighbors_Workshop`, `LogisticRegressionClassifier`  \n",
    "   - Copy the study guide from the course shell and save as **`StudyGuide.txt`**.  \n",
    "   - ZIP all *workshop* `.ipynb` files into **`StudyMaterials.zip`**.\n",
    "\n",
    "2. **Open a new LLM session** (model of your choice).  \n",
    "   Upload **`StudyGuide.txt`** and **`StudyMaterials.zip`**.\n",
    "\n",
    "3. **Run the prompt** from the section below.  \n",
    "   - The LLM will act as **interviewer + evaluator + tutor**.  \n",
    "   - It will **analyze materials**, **create a 500-word content summary**, **create a 100-word interview-topic summary**, and **check coverage vs. gaps**.  \n",
    "   - It will then **start a 15-question quiz** (one question at-a-time) **as soon as you're ready.**\n",
    "   - After the quiz, it will generate **JobInterviewGuide_Workshop.ipynb** tailored to your gaps.  \n",
    "   - In this notebook (the one you're reading), you'll **record your results** and complete **extra practice**.\n",
    "\n",
    "4. **Submit deliverable**  \n",
    "   - Push this notebook (updated with your results & exercises) to your GitHub repo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c26a2",
   "metadata": {},
   "source": [
    "\n",
    "## üìù Copy-Paste Prompt for Your LLM Session\n",
    "> Paste the following prompt into your LLM after uploading `StudyGuide.txt` and `StudyMaterials.zip`.\n",
    "\n",
    "```text\n",
    "You are a seasoned Data Scientist, Machine Learning Engineer, and technical interviewer.\n",
    "I am a Data Scientist and ML Engineer, fresh out of college. You will interview me for an ML Specialist role.\n",
    "\n",
    "1) Unzip and read StudyMaterials.zip. Understand the workshop notebooks it contains. Produce a **500-word summary** of the ML learning content and coding patterns.\n",
    "2) Read StudyGuide.txt. Produce a **100-word summary** of interview topics emphasized.\n",
    "3) **Match** the study guide topics to the workshop materials. Create a **table** listing each topic, whether it is covered by the materials, and any **gaps**.\n",
    "4) Create **15 multiple-choice questions** (A‚ÄìE) spanning: supervised vs. unsupervised, variables, train/val/test, linear & logistic regression (R¬≤, MSE, cross-entropy), KNN (hyperparams), decision trees (leaf nodes/predictions), plus **scenario-based/behavioral** items (e.g., imbalanced data, data leakage, model choice trade-offs). Ask **one question at a time**. After I answer all, **score me**.\n",
    "5) Based on questions I get wrong, generate a **new Jupyter Notebook** named **JobInterviewGuide_Workshop.ipynb** inside a folder **JobInterviewGuide_Workshop**. Include:\n",
    "   - Clear **Markdown explanations** of weak topics\n",
    "   - **Python code scaffolding** with exercises and TODOs\n",
    "   - Small, realistic examples and sanity checks\n",
    "   - A short **reflection** prompt about what I learned\n",
    "   - Use the style and structure of the workshop notebooks in the zip as inspiration.\n",
    "Stop here and **wait for my command to start the quiz**.\n",
    "```\n",
    "\n",
    "> When the LLM is ready, tell it to **begin the quiz**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a4ca6",
   "metadata": {},
   "source": [
    "\n",
    "## üßÆ Grading Rubric\n",
    "| Component | Description | Weight |\n",
    "|---|---|---|\n",
    "| **Quiz Performance** | Score across 15 technical + scenario/behavioral questions | **40%** |\n",
    "| **Generated Study Notebook Quality** | Accuracy, completeness, clarity, and relevance of the personalized notebook | **40%** |\n",
    "| **Reflection** | Insightful, concise self-assessment embedded at the end of this notebook | **20%** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65cb53",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Record Your Results (Complete After Quiz)\n",
    "> Fill in the fields below using your quiz report from the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üëâ Enter your results here after completing the quiz in your LLM session.\n",
    "quiz_results = {\n",
    "    \"name\": \"\",                  # Your name\n",
    "    \"date\": \"\",                  # YYYY-MM-DD\n",
    "    \"model_used\": \"\",            # e.g., GPT, Claude, Gemini\n",
    "    \"overall_score\": None,       # 0-100\n",
    "    \"num_correct\": None,         # out of 15\n",
    "    \"topics_missed\": [           # e.g., [\"Train/Val/Test\", \"Cross-Entropy\", \"KNN hyperparameters\"]\n",
    "    ],\n",
    "    \"behavioral_notes\": \"\",      # e.g., feedback on communication, trade-off reasoning\n",
    "    \"next_steps_from_llm\": \"\"    # LLM's guidance on what to practice\n",
    "}\n",
    "\n",
    "print('Recorded. You can re-run this cell to update later.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad1691",
   "metadata": {},
   "source": [
    "\n",
    "## üóÇ Coverage vs. Gaps (Paste from LLM)\n",
    "> Paste or recreate the **coverage table** generated by your LLM here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8742151",
   "metadata": {},
   "source": [
    "\n",
    "## ü™û Reflection (Required)\n",
    "Answer briefly (3‚Äì6 sentences):\n",
    "1. Which 1‚Äì2 concepts were most challenging, and why?\n",
    "2. What trade-offs or assumptions did you overlook in the interview?\n",
    "3. What is your plan to improve over the next week?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c6ceb0",
   "metadata": {},
   "source": [
    "\n",
    "## üß™ Targeted Practice (Complete These Exercises)\n",
    "> The exercises below scaffold practice for common weak areas. If your LLM-generated notebook adds more, do those as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2739c",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Train / Validation / Test Split & Data Leakage üî™\n",
    "- Implement a **stratified** train/val/test split for a binary classification dataset.\n",
    "- Show how **leakage** can happen if scaling is fit improperly.\n",
    "- Evaluate with **accuracy** and **cross-entropy** on val and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Implement proper stratified train/val/test split and demonstrate leakage vs. correct pipeline.\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# ‚úÖ Correct: fit scaler on train only via Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "val_pred_proba = pipe.predict_proba(X_val)[:,1]\n",
    "test_pred_proba = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "val_logloss = log_loss(y_val, val_pred_proba)\n",
    "test_logloss = log_loss(y_test, test_pred_proba)\n",
    "\n",
    "val_acc = accuracy_score(y_val, pipe.predict(X_val))\n",
    "test_acc = accuracy_score(y_test, pipe.predict(X_test))\n",
    "\n",
    "print({'val_logloss': val_logloss, 'test_logloss': test_logloss, 'val_acc': val_acc, 'test_acc': test_acc})\n",
    "\n",
    "# ‚ùå Leakage demo (anti-pattern): scaling fit on full data before split\n",
    "scaler = StandardScaler().fit(X)  # BAD: includes val/test info\n",
    "X_scaled = scaler.transform(X)\n",
    "X_tr_bad, X_te_bad, y_tr_bad, y_te_bad = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "clf_bad = LogisticRegression(max_iter=1000).fit(X_tr_bad, y_tr_bad)\n",
    "logloss_bad = log_loss(y_te_bad, clf_bad.predict_proba(X_te_bad)[:,1])\n",
    "acc_bad = accuracy_score(y_te_bad, clf_bad.predict(X_te_bad))\n",
    "print({'leakage_logloss': logloss_bad, 'leakage_acc': acc_bad})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043fa3db",
   "metadata": {},
   "source": [
    "\n",
    "### 2) Linear vs. Logistic Regression üìà‚û°Ô∏èüìä\n",
    "- Fit **linear regression** to a synthetic dataset; inspect **residuals** and discuss **linearization**.\n",
    "- Fit **logistic regression** to a classification dataset; interpret **intercept** and **slope** (weights) and compute **cross-entropy**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3935c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Residual analysis + logistic interpretation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, log_loss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Linear regression synthetic data\n",
    "Xr, yr = make_regression(n_samples=300, n_features=1, noise=15, random_state=7)\n",
    "lin = LinearRegression().fit(Xr, yr)\n",
    "yr_pred = lin.predict(Xr)\n",
    "\n",
    "print('Linear R^2:', r2_score(yr, yr_pred), 'MSE:', mean_squared_error(yr, yr_pred))\n",
    "\n",
    "# Residuals plot\n",
    "plt.figure()\n",
    "plt.scatter(yr_pred, yr - yr_pred, alpha=0.6)  # no specific colors\n",
    "plt.axhline(0)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residuals vs Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Logistic regression\n",
    "Xc, yc = make_classification(n_samples=400, n_features=4, n_informative=3, n_redundant=0, random_state=3)\n",
    "logit = LogisticRegression(max_iter=1000).fit(Xc, yc)\n",
    "proba = logit.predict_proba(Xc)[:,1]\n",
    "print('Cross-Entropy (log loss):', log_loss(yc, proba))\n",
    "print('Intercept:', logit.intercept_)  # Œ≤0\n",
    "print('Coefficients:', logit.coef_)    # Œ≤ (slopes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1547ba",
   "metadata": {},
   "source": [
    "\n",
    "### 3) KNN Hyperparameters & Decision Trees üå≥\n",
    "- For **KNN**, compare performance across different **k** and **distance metrics**; visualize validation performance.\n",
    "- For a **Decision Tree**, show **leaf nodes** and predicted labels; discuss **overfitting** and **max_depth**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: KNN sweep + Decision Tree visualization\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=0)\n",
    "\n",
    "ks = range(1, 21)\n",
    "val_scores = []\n",
    "for k in ks:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='minkowski')\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(ks), val_scores, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN Validation Accuracy vs k')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "dt.fit(X_train, y_train)\n",
    "print('Test accuracy:', accuracy_score(y_test, dt.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_tree(dt, feature_names=['sepal len','sepal wid','petal len','petal wid'], class_names=[str(i) for i in np.unique(y)], filled=False)\n",
    "plt.title('Decision Tree (max_depth=3)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02999e59",
   "metadata": {},
   "source": [
    "\n",
    "## üß∞ (Optional) Local Material Checks\n",
    "If you also have `StudyGuide.txt` and `StudyMaterials.zip` locally, you can use the helpers below to inspect them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPTIONAL: Inspect local files (if present)\n",
    "import os, zipfile, textwrap\n",
    "\n",
    "for fname in ['StudyGuide.txt', 'StudyMaterials.zip']:\n",
    "    print(f'{fname}:', 'FOUND' if os.path.exists(fname) else 'NOT FOUND')\n",
    "\n",
    "if os.path.exists('StudyGuide.txt'):\n",
    "    with open('StudyGuide.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = f.read(700)\n",
    "    print('\\n--- StudyGuide (first 700 chars) ---\\n')\n",
    "    print(textwrap.shorten(content, width=700))\n",
    "\n",
    "if os.path.exists('StudyMaterials.zip'):\n",
    "    with zipfile.ZipFile('StudyMaterials.zip', 'r') as z:\n",
    "        print('\\n--- ZIP Contents ---')\n",
    "        for info in z.infolist()[:30]:\n",
    "            print(info.filename, info.file_size, 'bytes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f6271",
   "metadata": {},
   "source": [
    "\n",
    "## üö¢ Submission (GitHub)\n",
    "- Ensure the notebook is **executed** and **saved** with your recorded results and completed exercises.\n",
    "- Add (in a new notebook called **JobInterviewLLMSession.ipynb**) the entire contents of the LLM session from start to end.\n",
    "- Push to your GitHub repository (replace remote and branch names as appropriate):\n",
    "\n",
    "```bash\n",
    "git add JobInterviewGuide_Workshop.ipynb \n",
    "git add JobInterviewLLMSession.ipynb\n",
    "git commit -m \"Add graded JobInterviewGuide_Workshop notebook and LLM session\"\n",
    "git push origin main\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
